from apiHelper import Comic
import csv
import requests
import pandas as pd
import os, sys

# modules for threading
import concurrent.futures
import threading
import time # simply

thread_local = threading.local()

comic_data_nlist = []

# threading
def get_session():
    if not hasattr(thread_local, "session"):
        thread_local.session = requests.Session()
    return thread_local.session


# Returns a list of data in the same order as the csv file
def get_comic_data(comic_num):
    comic_data = Comic(num=comic_num)
    global comic_data_nlist

    data = [
        comic_data.num, # Comic Number
        comic_data.title, # Comic Title 
        comic_data.img, # url to the comic image
        comic_data.trans, # transcript provided thorugh api
        comic_data.alt, # alt text provided by api
        comic_data.content # text generated by the OCR
    ]
    print(f"Data for comic {comic_num} fetched sucessfully")
    # print("Data for comic {num} fetched sucessfully (OCR)")
    comic_data_nlist.append(data)


# Threading function to get all comcis
def fetch_all_comics(nums_list):
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        executor.map(get_comic_data, nums_list)

    print("++++++ APPENDING & UPDATING COMICS +++++++")


# Checks the latest comic in the local reference
def latest_in_db():
    df = pd.read_csv('./src/resources/comics.csv', header=0, names=['Number', 'Title', 'Img', 'Transcript', 'Alt', 'Content'])
    # df.set_index('Number', inplace=True)
    return max(df['Number'].tolist())


# Finds the latest comics number
def latest_online():
    latest = latest_in_db()
    found = False
    while not found:
        latest += 1
        if requests.get(f"https://xkcd.com/{latest}/info.0.json").status_code == 404:
            found = True
    return latest - 1


# Function to update the csv file
# Making use of threading functions above
def update_storage():

    global comic_data_nlist
    
    # when we call the list, clear the previous contents if any
    comic_data_nlist = []
    
    # if comic 2854 exists, we want to start appending from 2855 into the csv
    range_list = list(range(latest_in_db() + 1, latest_online() + 1))
    range_list = list(
        set(range(latest_in_db() + 1, latest_online() + 1)).difference({404})
    )

    fetch_all_comics(nums_list=range_list)

    if sys.platform in ['darwin', 'linux']:
        os.system('clear')
    else:
        os.system('cls')


    with open('./src/resources/comics.csv', 'a') as f:
        csv.writer(f).writerows(comic_data_nlist)
